<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Intermediate IV: objective states · SDDP.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>SDDP.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">Tutorials</span><ul><li><span class="toctext">Basic</span><ul><li><a class="toctext" href="../01_first_steps/">Basic I: first steps</a></li><li><a class="toctext" href="../02_adding_uncertainty/">Basic II: adding uncertainty</a></li><li><a class="toctext" href="../03_objective_uncertainty/">Basic III: objective uncertainty</a></li><li><a class="toctext" href="../04_markov_uncertainty/">Basic IV: Markov uncertainty</a></li><li><a class="toctext" href="../05_plotting/">Basic V: plotting</a></li><li><a class="toctext" href="../06_warnings/">Basic VI: words of warning</a></li><li><a class="toctext" href="../07_advanced_modelling/">Basic VII: modelling tips</a></li></ul></li><li><span class="toctext">Intermediate</span><ul><li><a class="toctext" href="../11_risk/">Intermediate I: risk</a></li><li><a class="toctext" href="../12_stopping_rules/">Intermediate II: stopping rules</a></li><li><a class="toctext" href="../13_generic_graphs/">Intermediate III: policy graphs</a></li><li class="current"><a class="toctext" href>Intermediate IV: objective states</a><ul class="internal"><li><a class="toctext" href="#One-dimensional-objective-states-1">One-dimensional objective states</a></li><li><a class="toctext" href="#Multi-dimensional-objective-states-1">Multi-dimensional objective states</a></li><li><a class="toctext" href="#objective_state_warnings-1">Warnings</a></li></ul></li><li><a class="toctext" href="../15_performance/">Intermediate V: performance</a></li></ul></li></ul></li><li><a class="toctext" href="../../apireference/">Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li>Tutorials</li><li>Intermediate</li><li><a href>Intermediate IV: objective states</a></li></ul><a class="edit-page" href="https://github.com/odow/Kokako.jl/blob/master/docs/src/tutorial/14_objective_states.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Intermediate IV: objective states</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Intermediate-IV:-objective-states-1" href="#Intermediate-IV:-objective-states-1">Intermediate IV: objective states</a></h1><p>There are many applications in which we want to model a price process that follows some auto-regressive process. Common examples include stock prices on financial exchanges and spot-prices in energy markets.</p><p>However, it is well known that these cannot be incorporated in to SDDP because they result in cost-to-go functions that are convex with respect to some state variables (e.g., the reservoir levels) and concave with respect to other state variables (e.g., the spot price in the current stage).</p><p>To overcome this problem, the approach in the literature has been to discretize the price process in order to model it using a Markovian policy graph like those discussed in <a href="../04_markov_uncertainty/#Basic-IV:-Markov-uncertainty-1">Basic IV: Markov uncertainty</a>.</p><p>However, recent work offers a way to include stagewise-dependent objective uncertainty into the objective function of SDDP subproblems. Readers are directed to the following works for an introduction:</p><ul><li><p>Downward, A., Dowson, O., and Baucke, R. (2017). Stochastic dual dynamic programming with stagewise dependent objective uncertainty. Optimization Online. <a href="http://www.optimization-online.org/DB_HTML/2018/02/6454.html">link</a></p></li><li><p>Dowson, O. PhD Thesis. University of Auckland, 2018. <a href="https://researchspace.auckland.ac.nz/handle/2292/37700">link</a></p></li></ul><p>The method discussed in the above works introduces the concept of an <em>objective state</em> into SDDP. Unlike normal state variables in SDDP (e.g., the volume of water in the reservoir), the cost-to-go function is <em>concave</em> with respect to the objective states. Thus, the method builds an outer approximation of the cost-to-go function in the normal state-space, and an inner approximation of the cost-to-go function in the objective state-space.</p><div class="admonition warn"><div class="admonition-title">Warn</div><div class="admonition-text"><p>Support for objective states in <code>SDDP.jl</code> is experimental. Models are considerably more computational intensive, the interface is less user-friendly, and there are <a href="#objective_state_warnings-1">subtle gotchas to be aware of</a>. Only use this if you have read and understood the theory behind the method.</p></div></div><h2><a class="nav-anchor" id="One-dimensional-objective-states-1" href="#One-dimensional-objective-states-1">One-dimensional objective states</a></h2><p>Let&#39;s assume that the fuel cost is not fixed, but instead evolves according to a multiplicative auto-regressive process: <code>fuel_cost[t] = ω * fuel_cost[t-1]</code>, where <code>ω</code> is drawn from the sample space <code>[0.75, 0.9, 1.1, 1.25]</code> with equal probability.</p><p>An objective state can be added to a subproblem using the <a href="../../apireference/#Kokako.add_objective_state"><code>Kokako.add_objective_state</code></a> function. This can only be called once per subproblem. If you want to add a multi-dimensional objective state, read <a href="#Multi-dimensional-objective-states-1">Multi-dimensional objective states</a>. <a href="../../apireference/#Kokako.add_objective_state"><code>Kokako.add_objective_state</code></a> takes a number of keyword arguments. The two required ones are</p><ul><li><p><code>initial_value</code>: the value of the objective state at the root node of the policy graph (i.e., identical to the <code>initial_value</code> when defining normal state variables.</p></li><li><p><code>lipschitz</code>: the Lipschitz constant of the cost-to-go function with respect to the objective state. In other words, this value is the maximum change in the cost-to-go function <em>at any point in the state space</em>, given a one-unit change in the objective state.</p></li></ul><p>There are also two optional keyword arguments: <code>lower_bound</code> and <code>upper_bound</code>, which give SDDP.jl hints (importantly, not constraints) about the domain of the objective state. Setting these bounds appropriately can improve the speed of convergence.</p><p>Finally, <a href="../../apireference/#Kokako.add_objective_state"><code>Kokako.add_objective_state</code></a> requires an update function. This function takes two arguments. The first is the incoming value of the objective state, and the second is the realization of the stagewise-independent noise term (set using <a href="../../apireference/#Kokako.parameterize"><code>Kokako.parameterize</code></a>). The function should return the value of the objective state to be used in the current subproblem.</p><p>This connection with the stagewise-independent noise term means that <a href="../../apireference/#Kokako.parameterize"><code>Kokako.parameterize</code></a> <em>must</em> be called in a subproblem that defines an objective state. Inside <a href="../../apireference/#Kokako.parameterize"><code>Kokako.parameterize</code></a>, the value of the objective state to be used in the current subproblem (i.e., after the update function), can be queried using <a href="../../apireference/#Kokako.objective_state"><code>Kokako.objective_state</code></a>.</p><p>Here is the full model with the objective state.</p><pre><code class="language-julia">using Kokako, GLPK

model = Kokako.LinearPolicyGraph(
            stages = 3, sense = :Min, lower_bound = 0.0,
            optimizer = with_optimizer(GLPK.Optimizer)
        ) do subproblem, t
    @variable(subproblem, 0 &lt;= volume &lt;= 200, Kokako.State, initial_value = 200)
    @variables(subproblem, begin
        thermal_generation &gt;= 0
        hydro_generation   &gt;= 0
        hydro_spill        &gt;= 0
        inflow
    end)
    @constraints(subproblem, begin
        volume.out == volume.in + inflow - hydro_generation - hydro_spill
        demand_constraint, thermal_generation + hydro_generation == 150.0
    end)

    ###
    ### Add an objective state. ω will be the same value that is called in
    ### `Kokako.parameterize`.
    ###

    Kokako.add_objective_state(
            subproblem, initial_value = 50.0, lipschitz = 10_000.0,
            lower_bound = 50.0, upper_bound = 150.0) do fuel_cost, ω
        return ω.fuel * fuel_cost
    end

    ###
    ### Create the cartesian product of a multi-dimensional random variable.
    ###

    Ω = [
        (fuel = f, inflow = w)
        for f in [0.75, 0.9, 1.1, 1.25] for w in [0.0, 50.0, 100.0]
    ]

    Kokako.parameterize(subproblem, Ω) do ω
        ###
        ### Query the current fuel cost.
        ###

        fuel_cost = Kokako.objective_state(subproblem)

        @stageobjective(subproblem, fuel_cost * thermal_generation)
        JuMP.fix(inflow, ω.inflow)
    end
end

# output

A policy graph with 3 nodes.
 Node indices: 1, 2, 3</code></pre><p>After creating our model, we can train and simulate as usual.</p><pre><code class="language-julia">Kokako.train(model, iteration_limit = 10, perform_numerical_stability_check=false)

simulations = Kokako.simulate(model, 1)

print(&quot;Finished training and simulating.&quot;)

# output

———————————————————————————————————————————————————————————————————————————————
                        SDDP.jl - © Oscar Dowson, 2017-19.
———————————————————————————————————————————————————————————————————————————————
 Iteration | Simulation |      Bound |   Time (s)
———————————————————————————————————————————————————————————————————————————————
         1 |     7.031K |     4.018K |     0.029
         2 |     0.000  |     4.557K |     0.031
         3 |     4.171K |     4.573K |     0.034
         4 |     7.148K |     4.573K |     0.036
         5 |     0.000  |     4.573K |     0.038
         6 |     1.822K |     4.573K |     0.041
         7 |     2.109K |     4.573K |     0.043
         8 |     7.481K |     4.573K |     0.045
         9 |     5.231K |     4.573K |     0.048
        10 |     6.300K |     4.573K |     0.050
———————————————————————————————————————————————————————————————————————————————
 Terminating training with status: iteration_limit
———————————————————————————————————————————————————————————————————————————————
Finished training and simulating.</code></pre><p>To demonstrate how the objective states are updated, consider the sequence of noise observations:</p><pre><code class="language-julia-repl">julia&gt; [stage[:noise_term] for stage in simulations[1]]
3-element Array{NamedTuple{(:fuel, :inflow),Tuple{Float64,Float64}},1}:
 (fuel = 0.75, inflow = 0.0)
 (fuel = 0.9, inflow = 50.0)
 (fuel = 1.25, inflow = 50.0)</code></pre><p>This, the fuel cost in the first stage should be <code>0.75 * 50 = 37.5</code>. The fuel cost in the second stage should be <code>0.9 * 37.5 = 33.75</code>. The fuel cost in the third stage should be <code>1.25 * 33.75 = 42.1875</code>.</p><p>To confirm this, the values of the objective state in a simulation can be queried using the <code>:objective_state</code> key.</p><pre><code class="language-julia-repl">julia&gt; [stage[:objective_state] for stage in simulations[1]]
3-element Array{Float64,1}:
 37.5
 33.75
 42.1875</code></pre><h2><a class="nav-anchor" id="Multi-dimensional-objective-states-1" href="#Multi-dimensional-objective-states-1">Multi-dimensional objective states</a></h2><p>You can construct multi-dimensional price processes using <code>NTuple</code>s. Just replace every scalar value associated with the objective state by a tuple. For example, <code>initial_value = 1.0</code> becomes <code>initial_value = (1.0, 2.0)</code>.</p><p>Here is an example:</p><pre><code class="language-julia">model = Kokako.LinearPolicyGraph(
            stages = 3, sense = :Min, lower_bound = 0.0,
            optimizer = with_optimizer(GLPK.Optimizer)
        ) do subproblem, t
    @variable(subproblem, 0 &lt;= volume &lt;= 200, Kokako.State, initial_value = 200)
    @variables(subproblem, begin
        thermal_generation &gt;= 0
        hydro_generation   &gt;= 0
        hydro_spill        &gt;= 0
        inflow
    end)
    @constraints(subproblem, begin
        volume.out == volume.in + inflow - hydro_generation - hydro_spill
        demand_constraint, thermal_generation + hydro_generation == 150.0
    end)

    Kokako.add_objective_state(
            subproblem, initial_value = (50.0, 50.0),
            lipschitz = (10_000.0, 10_000.0), lower_bound = (50.0, 50.0),
            upper_bound = (150.0, 150.0)) do fuel_cost, ω
        fuel_cost′ = fuel_cost[1] + 0.5 * (fuel_cost[1] - fuel_cost[2]) + ω.fuel
        return (fuel_cost′, fuel_cost[1])
    end

    Ω = [
        (fuel = f, inflow = w)
        for f in [-10.0, -5.0, 5.0, 10.0] for w in [0.0, 50.0, 100.0]
    ]

    Kokako.parameterize(subproblem, Ω) do ω
        (fuel_cost, fuel_cost_old) = Kokako.objective_state(subproblem)
        @stageobjective(subproblem, fuel_cost * thermal_generation)
        JuMP.fix(inflow, ω.inflow)
    end
end

Kokako.train(model, iteration_limit = 10, perform_numerical_stability_check=false)

simulations = Kokako.simulate(model, 1)

print(&quot;Finished training and simulating.&quot;)

# output

———————————————————————————————————————————————————————————————————————————————
                        SDDP.jl - © Oscar Dowson, 2017-19.
———————————————————————————————————————————————————————————————————————————————
 Iteration | Simulation |      Bound |   Time (s)
———————————————————————————————————————————————————————————————————————————————
         1 |     7.031K |     4.018K |     0.029
         2 |     0.000  |     4.557K |     0.031
         3 |     4.171K |     4.573K |     0.034
         4 |     7.148K |     4.573K |     0.036
         5 |     0.000  |     4.573K |     0.038
         6 |     1.822K |     4.573K |     0.041
         7 |     2.109K |     4.573K |     0.043
         8 |     7.481K |     4.573K |     0.045
         9 |     5.231K |     4.573K |     0.048
        10 |     6.300K |     4.573K |     0.050
———————————————————————————————————————————————————————————————————————————————
 Terminating training with status: iteration_limit
———————————————————————————————————————————————————————————————————————————————
Finished training and simulating.</code></pre><p>This time, since our objective state is two-dimensional, the objective states are tuples with two elements:</p><pre><code class="language-julia-repl">julia&gt; [stage[:objective_state] for stage in simulations[1]]
3-element Array{Tuple{Float64,Float64},1}:
 (55.0, 50.0)
 (52.5, 55.0)
 (56.25, 52.5)</code></pre><h2><a class="nav-anchor" id="objective_state_warnings-1" href="#objective_state_warnings-1">Warnings</a></h2><p>There are number of things to be aware of when using objective states.</p><ul><li><p>The key assumption is that price is independent of the states and actions in  the model.</p><p>That means that the price cannot appear in any <code>@constraint</code>s. Nor can you  use any <code>@variable</code>s in the update function.</p></li><li><p>Choosing an appropriate Lipschitz constant is difficult.</p><p>The points discussed in <a href="../06_warnings/#Choosing-an-initial-bound-1">Choosing an initial bound</a> are relevant. The  Lipschitz constant should not be chosen as large as possible (since this  will help with convergence and the numerical issues discussed above), but if  chosen to small, it may cut of the feasible region and lead to a sub-optimal  solution.</p></li><li><p>You need to ensure that the cost-to-go function is concave with respect to  the objective state <em>before</em> the update.</p><p><span>$V(x, y) = \min\{Y(y)&#39; x \;|\; Ax \ge b\}$</span></p><p>If the update function is linear, this is always the case. In some  situations, the update function can be nonlinear (e.g., multiplicative as we  have above). In general, placing constraints on the price (e.g.,  <code>clamp(price, 0, 1)</code>) will destroy concavity. <a href="https://en.wikipedia.org/wiki/Caveat_emptor">Caveat  emptor</a>. It&#39;s up to you if this  is a problem. If it isn&#39;t you&#39;ll get a good heuristic with no guarantee of  global optimality.</p></li></ul><p>In the next tutorial, <a href="../15_performance/#Intermediate-V:-performance-1">Intermediate V: performance</a>, we discuss how to improve the computational performance of <code>SDDP.jl</code> models.</p><footer><hr/><a class="previous" href="../13_generic_graphs/"><span class="direction">Previous</span><span class="title">Intermediate III: policy graphs</span></a><a class="next" href="../15_performance/"><span class="direction">Next</span><span class="title">Intermediate V: performance</span></a></footer></article></body></html>
